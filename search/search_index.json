{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"oarfish: transcript quantification from long-read RNA-seq data","text":"<p><code>oarfish</code> is a program, written in Rust (https://www.rust-lang.org/), for quantifying transcript-level expression from long-read (i.e. Oxford nanopore cDNA and direct RNA and PacBio) sequencing technologies. <code>oarfish</code> requires a sample of sequencing reads aligned to the transcriptome (currntly not to the genome). It handles multi-mapping reads through the use of probabilistic allocation via an expectation-maximization (EM) algorithm.</p> <p>It optionally employs many filters to help discard alignments that may reduce quantification accuracy. Currently, the set of filters applied in <code>oarfish</code> are directly derived from the <code>NanoCount</code><sup>1</sup> tool; both the filters that exist, and the way their values are set (with the exception of the <code>--three-prime-clip</code> filter, which is not set by default in <code>oarfish</code> but is in <code>NanoCount</code>).</p> <p>Additionally, <code>oarfish</code> provides options to make use of coverage profiles derived from the aligned reads to improve quantification accuracy. The use of this coverage model is enabled with the <code>--model-coverage</code> flag. You can read more about <code>oarfish</code><sup>2</sup> in the preprint. Please cite the preprint if you use <code>oarfish</code> in your work or analysis.</p> <p>Also, please note that <code>oarfish</code> is scientific software in active development. Therefore, please check the GitHub Release page to make sure that you are using the latest version</p>"},{"location":"#installation","title":"Installation","text":"<p><code>oarfish</code> can be installed in a variety of ways.</p>"},{"location":"#precompiled-binaries","title":"Precompiled binaries","text":"<p>Binaries are available via GitHub Releases.</p> <p>You can quickly install the latest release using the following helper script:</p> <pre><code>curl --proto '=https' --tlsv1.2 -LsSf https://github.com/COMBINE-lab/oarfish/releases/latest/download/oarfish-installer.sh | sh\n</code></pre>"},{"location":"#using-cargo","title":"Using <code>cargo</code>","text":"<p>If you have <code>cargo</code> installed, you can install <code>oarfish</code> directly from the source code:</p> <pre><code>cargo install oarfish\n</code></pre> <p>You can find the crate on crates.io.</p>"},{"location":"#bioconda","title":"Bioconda","text":"<p><code>oarfish</code> is available via Bioconda:</p> <pre><code>conda install -c bioconda oarfish\n</code></pre>"},{"location":"#basic-usage","title":"Basic usage","text":"<p>The usage can be provided by passing <code>-h</code> at the command line.</p> <pre><code>A fast, accurate and versatile tool for long-read transcript quantification.\n\nUsage: oarfish [OPTIONS] --output &lt;OUTPUT&gt; &lt;--alignments &lt;ALIGNMENTS&gt;|--reads &lt;READS&gt;&gt;\n\nOptions:\n      --quiet\n          be quiet (i.e. don't output log messages that aren't at least warnings)\n      --verbose\n          be verbose (i.e. output all non-developer logging messages)\n  -o, --output &lt;OUTPUT&gt;\n          location where output quantification file should be written\n      --single-cell\n          input is assumed to be a single-cell BAM and to have the `CB:z` tag for all read records\n  -j, --threads &lt;THREADS&gt;\n          number of cores that oarfish will use during different phases of quantification. Note: This value will be at least 2 for bulk quantification and at least 3 for single-cell quantification due to the use of d\nedicated parsing threads [default: 3]\n      --num-bootstraps &lt;NUM_BOOTSTRAPS&gt;\n          number of bootstrap replicates to produce to assess quantification uncertainty [default: 0]\n  -h, --help\n          Print help\n  -V, --version\n          Print version\n\nalignment mode:\n  -a, --alignments &lt;ALIGNMENTS&gt;  path to the file containing the input alignments\n\nraw read mode:\n      --reads &lt;READS&gt;          path to the file containing the input reads\n      --reference &lt;REFERENCE&gt;  path to the file containing the reference transcriptome (or existing index) against which to map\n      --index-out &lt;INDEX_OUT&gt;  path where minimap2 index will be written (if provided)\n      --seq-tech &lt;SEQ_TECH&gt;    sequencing technology in which to expect reads if using mapping based mode [possible values: ont-cdna, ont-drna, pac-bio, pac-bio-hifi]\n      --best-n &lt;BEST_N&gt;        maximum number of secondary mappings to consider when mapping reads to the transcriptome [default: 100]\n\nfilters:\n      --filter-group &lt;FILTER_GROUP&gt;\n          [possible values: no-filters, nanocount-filters]\n  -t, --three-prime-clip &lt;THREE_PRIME_CLIP&gt;\n          maximum allowable distance of the right-most end of an alignment from the 3' transcript end [default: *4294967295]\n  -f, --five-prime-clip &lt;FIVE_PRIME_CLIP&gt;\n          maximum allowable distance of the left-most end of an alignment from the 5' transcript end [default: *4294967295]\n  -s, --score-threshold &lt;SCORE_THRESHOLD&gt;\n          fraction of the best possible alignment score that a secondary alignment must have for consideration [default: *0.95]\n  -m, --min-aligned-fraction &lt;MIN_ALIGNED_FRACTION&gt;\n          fraction of a query that must be mapped within an alignemnt to consider the alignemnt valid [default: *0.5]\n  -l, --min-aligned-len &lt;MIN_ALIGNED_LEN&gt;\n          minimum number of nucleotides in the aligned portion of a read [default: *50]\n  -d, --strand-filter &lt;STRAND_FILTER&gt;\n          only alignments to this strand will be allowed; options are (fw /+, rc/-, or both/.) [default: .]\n\ncoverage model:\n      --model-coverage         apply the coverage model\n  -b, --bin-width &lt;BIN_WIDTH&gt;  width of the bins used in the coverage model [default: 100]\n\noutput read-txps probabilities:\n      --write-assignment-probs[=&lt;WRITE_ASSIGNMENT_PROBS&gt;]\n          write output alignment probabilites (optionally compressed) for each mapped read\n\nEM:\n      --max-em-iter &lt;MAX_EM_ITER&gt;\n          maximum number of iterations for which to run the EM algorithm [default: 1000]\n      --convergence-thresh &lt;CONVERGENCE_THRESH&gt;\n          maximum number of iterations for which to run the EM algorithm [default: 0.001]\n  -q, --short-quant &lt;SHORT_QUANT&gt;\n          location of short read quantification (if provided)\n</code></pre>"},{"location":"#usage-examples","title":"Usage examples","text":"<p>Assume that you have ONT cDNA sequencing reads in a file named <code>sample1_reads.fq.gz</code>, and you'd like to quantify the transcripts in a transcriptome reference in the file <code>transcripts.fa</code>. To accomplish this with oarfish, you can use either alignment-based or read-based mode.  Here we give a brief example of each.  To use alignment-based mode, we assume you have minimap2 and samtools installed.  </p>"},{"location":"#aligment-mode-example","title":"aligment-mode example","text":"<p>You can quantify the transcript abundances in this sample using the following commands:</p> <pre><code>$ minimap2 -t 16 -ax map-ont transcripts.fa sample1_reads.fq.gz | samtools view -@4 -b -o alignments.bam\n$ oarfish -j 16 -a alignments.bam -o sample1 --filter-group no-filters --model-coverage\n</code></pre> <p>This will produce several output files, as described below.</p>"},{"location":"#read-mode-example","title":"read-mode example","text":"<p>In read-based mode, you can quantify the transcript abundances in this sample using the following commands:</p> <pre><code>$ oarfish -j 16 --reads sample1_reads.fq.gz --reference transcripts.fa --seq-tech ont-cdna -o sample1 --filter-group no-filters --model-coverage\n</code></pre> <p>If you are going to quantify more than one sample against these reference transcripts, it makes sense to save the minimap2 index that the above command creates.  This can be done using the following command:</p> <pre><code>$ oarfish -j 16 --reads sample1_reads.fq.gz --reference transcripts.fa --index-out transcripts.mmi --seq-tech ont-cdna -o sample1 --filter-group no-filters --model-coverage\n</code></pre> <p>Then, in subsequent runs (say when quantifying <code>sample2_reads.fq.gz</code>), you can directly provide the <code>minimap2</code> index in place of the reference to speed up quantification.  That command would look like the following:</p> <pre><code>$ oarfish -j 16 --reads sample2_reads.fq.gz --reference transcripts.mmi --seq-tech ont-cdna -o sample2 --filter-group no-filters --model-coverage\n</code></pre> <p>As with alignment-based mode, these commands will produce several output files, as described below.</p>"},{"location":"#input-to-oarfish","title":"Input to <code>oarfish</code>","text":"<p><code>Oarfish</code> can accept as input either a <code>bam</code> file containing reads aligned to the transcriptome as specified below, or raw sequencing reads themselves (along with a reference transcriptome), which are then mapped to the reference using minimap2-rs and subsequently processed with <code>oarfish</code>.  With equivalent alignment options, the results of these input modes should be equivalent, so which to use is therefore based on the preference of the user.</p>"},{"location":"#read-based-input","title":"Read-based input","text":"<p>The read-based input mode takes as input a reference (specified with the <code>--reference</code> argument), which can be either a <code>FASTA</code> file containing a transcriptome reference or an pre-build <code>minimap2</code> index, as well as a set of reads (specified with the <code>--reads</code> argument), and a <code>--seq-tech</code> argument specifying the sequencing technology  type of the reads to be mapped.</p> <p>The mapping between the potential values that can be passed to <code>oarfish</code>'s <code>--seq-tech</code> argument and the <code>minimap2</code> presets is as follows:</p> <ul> <li><code>oarfish</code> seq-tech <code>ont-cdna</code> corresponds to <code>minimap2</code> preset <code>map-ont</code></li> <li><code>oarfish</code> seq-tech <code>ont-drna</code> corresponds to <code>minimap2</code> preset <code>map-ont</code></li> <li><code>oarfish</code> seq-tech <code>pac-bio</code> corresponds to <code>minimap2</code> preset <code>map-pb</code></li> <li><code>oarfish</code> seq-tech <code>pac-bio-hifi</code> corresponds to <code>minimap2</code> preset <code>map-hifi</code></li> </ul> <p>Given these inputs, <code>oarfish</code> will either load the pre-built <code>minimap2</code> index, or build one according to the parameter specified by <code>--seq-tech</code>, and will then align the reads to this index using <code>minimap2-rs</code>.  Optionally, the maximum multimapping rate (i.e. the number of secondary alignments  corresponding to the <code>minimap2</code> parameter <code>-N</code>) can be specified with the command line parameter <code>--best-n</code>. The default value of this parameter is 100.</p>"},{"location":"#read-based-input-formats","title":"Read-based input formats","text":"<p><code>oarfish</code> is capable of taking input in either <code>FASTA</code> format <code>FASTQ</code> format, or unaligned <code>BAM</code> (<code>uBAM</code>) format.  When you pass the raw reads to <code>oarfish</code> via the <code>--reads</code> flag, <code>oarfish</code> will attempt to infer the type of the input by looking at the file suffix.  If it matches one of <code>.fa</code>, <code>.fasta</code>, <code>.FA</code>, <code>.FASTA</code>, <code>.fq</code>, <code>.fastq</code>, <code>.FQ</code>, <code>.FASTQ</code>, <code>.fa.gz</code>, <code>.fasta.gz</code>, <code>.FA.GZ</code>, <code>.FASTA.GZ</code>, <code>.fq.gz</code>, <code>.fastq.gz</code>, <code>.FQ.GZ</code>, or <code>.FASTQ.GZ</code>, then the input file will be assumed to be an (appropriately compressed) <code>FASTA</code> or <code>FASTQ</code> format. Otherwise, if it ends in <code>.bam</code> or <code>.ubam</code> or <code>.BAM</code> or <code>.UBAM</code>, it will be assumed to be in <code>uBAM</code> format. If  the format cannot be inferred via the file suffix (e.g. if the file is being provided via process substitution), then an attempt will be made to parse it as a (possibly compressed) <code>FASTA</code>/<code>FASTQ</code> format file.</p>"},{"location":"#alignmment-based-input","title":"Alignmment-based input","text":"<p>In alignment-based mode, <code>oarfish</code> processes pre-computed alignments of hte read to the transcriptome. The input should be a <code>bam</code> format file, with reads aligned using <code>minimap2</code> against the transcriptome. That is, <code>oarfish</code> does not currently handle spliced alignment to the genome. Further, the output alignments should be name sorted (the default order produced by <code>minimap2</code> should be fine). Specifically, <code>oarfish</code> relies on the existence of the <code>AS</code> tag in the <code>bam</code> records that encodes the alignment score in order to obtain the score for each alignment (which is used in probabilistic read assignment), and the score of the best alignment, overall, for each read. ### Choosing <code>minimap2</code> alignment options Since the purpose of <code>oarfish</code> is to estimate transcript abundance from a collection of alignments to the target transcriptome, it is important that the alignments are generated in a fashion that is compatible with this goal.  Primarily, this means that the aligner should be configured to report as many optimal (and near-optimal) alignments as exist, so that <code>oarfish</code> can observe all of this information and determine how to allocate reads to transcripts.  We recommend using the following options with <code>minimap2</code> when aligning data for later processing by <code>oarfish</code> * For ONT data (either dRNA or cDNA): please use the flags <code>--eqx -N 100 -ax map-ont</code> For PacBio data: please use the flags <code>--eqx -N 100 -ax pacbio</code> Note (1): It may be worthwile using an even larger <code>N</code> value (e.g. the TranSigner manuscript recommends <code>-N 181</code>). A larger value should not diminish the accuracy of <code>oarfish</code>, but it may make alignment take longer and produce a larger <code>bam</code> file.</p> <p>Note (2): For very high quality PacBio data, it may be most appropriate to use the <code>-ax map-hifi</code> flag in place of <code>-ax pacbio</code>.  We are currently evaluating the effect of this option, and also welcome feedback if you have experiences to share on the use of data aligned with these different flags with <code>oarfish</code>.</p>"},{"location":"#other-notes-on-oarfish-parameters","title":"Other notes on <code>oarfish</code> parameters","text":"<p>The parameters above should be explained by their relevant help option, but the <code>-d</code>/<code>--strand-filter</code> is worth noting explicitly. By default, alignments to both strands of a transcript will be considered valid.  You can use this option to allow only alignments in the specified orientation; for example <code>-d fw</code> will allow only alignments in the forward orientation and <code>-d rc</code> will allow only alignments in the reverse-complement orientation and <code>-d both</code> (the default) will allow both.  The <code>-d</code> filter, if explicitly provided, overrides the orientation filter in any provided \"filter group\" so e.g. passing <code>--filter-group no-filters -d fw</code> will disable other filters, but will still only admit alignments in the forward orientation.</p> <p>In general, if you apply a <code>filter-group</code>, the group options will be applied first and then any explicitly provided options given will override the corresponding option in the <code>filter-group</code>.</p>"},{"location":"#read-level-assignment-probabilities","title":"Read-level assignment probabilities","text":"<p><code>oarfish</code> has the ability to output read-level assignment probabilities.  That is, for each input read, what is the probability, conditioned on the final estimate of transcript abundances, that the read was sequenced from each transcript to which it aligned. By default, this information is not recorded (as it's not required, or commonly used, for most standard analyses). To enable this output, you should pass the <code>--write-assignment-probs</code> option to <code>oarfish</code>.  Optionally, you may also pass <code>--write-assignment-probs=compressed</code> to write the output to a compressed (lz4) stream --- the default output is to an uncompressed text file.</p> <p>The format of the read assignment probabilities is as follows --- where all fields below on a single line are <code>\\t</code> delimited:</p> <pre><code>&lt;m&gt; &lt;n&gt;\n&lt;tname_1&gt;\n&lt;tname_2&gt;\n...\n&lt;tname_m&gt;\n&lt;rname_1&gt; &lt;k_1&gt; &lt;tid_11&gt; &lt;tid_21&gt; ... &lt;tid_{k_1}1&gt; &lt;p_11&gt; &lt;p_21&gt; ... &lt;p_{k_1}1&gt;\n...\n&lt;rname_n&gt; &lt;k_1&gt; &lt;tid_1n&gt; &lt;tid_2n&gt; ... &lt;tid_{k_n}n&gt; &lt;p_1n&gt; &lt;p_2n&gt; ... &lt;p_{k_n}n&gt;\n</code></pre> <p>Here, <code>&lt;m&gt;</code> is the number of transcripts in the reference, <code>&lt;n&gt;</code> is the number of mapped reads. The following <code>m</code> lines consist of the names of the transcripts in the order they will be referred to in the file. The following <code>n</code> lines after that provide the actual alignment information and assignment probabilities for each read.</p> <p>The format of each of these lines is as follows; <code>&lt;rname&gt;</code> is the name of the read, <code>&lt;k&gt;</code> is the number of alignments for which probabilities are reported (if it is determined an alignment is invalid under the model, it may not be reported). Subsequently, there is a list of <code>k</code> integers, and <code>k</code> floating point numbers. Each of the <code>k</code> integers is the index of some transcript in the list of <code>m</code> transcripts given at the start of the file, and the subsequent list of <code>k</code> floating point numbers are the assignment probabilities of this read to each of the transcripts.</p> <p>For example:</p> <pre><code>5 3\ntxpA\ntxpB\ntxpC\ntxpD\ntxpE\nreadX 2 0 2 0.4 0.6\nreadY 3 1 3 4 0.1 0.2 0.7\nreadZ 1 4 1.0\n</code></pre> <p>This file provides an example with 5 reference transcripts and 3 mapped reads. The first read (readX) maps to transcripts 0 and 2 (so txpA and txpC) with probabilities 0.4 and 0.6 respectively. The next read (readY) maps to 3 transcripts, txpB, txpD and txpE with probabilities 0.1, 0.2, and 0.7 respectively. Finally, the last read (readZ) maps uniquely to transcript txpE with probability 1.</p> <p>The compressed output (i.e. what is generated if one passes <code>--write-assignment-probs=compressed</code>) is exactly the same format, except instead of residing in a plain text file, it is written to an lz4 compressed text file.  You can either decompress this file first with an lz4 decompressor, or decompress it on-the-fly as you are parsing the file using the lz4 library in your favorite language.</p>"},{"location":"#notes-about-single-cell-mode","title":"Notes about single-cell mode","text":"<p>Starting with version 0.6.1 <code>oarfish</code> incorporates the first single-cell quantification capabilities. Given a <code>bam</code> file, collated by cell barcode and with already (UMI) deduplicated reads, this mode, enabled with the <code>--single-cell</code> flag, will allow <code>oarfish</code> to produce a single-cell quantification matrix. Currently, this mode can not be used with read-based mode, and the input <code>bam</code> file should be properly formatted for this purpose. </p> <p>Formatting requirements of BAM input in single-cell mode: All alignment records for the same cell barcode should be adjacent in the <code>bam</code> file, and a count will be obtained for each read record, so UMI de-duplication should have been performed if those are the counts you want. In the future, counting UMIs directly may be supported, and some of these other restrictions may be lifted.</p>"},{"location":"#inferential-replicates","title":"Inferential Replicates","text":"<p><code>oarfish</code> has the ability to compute inferential replicates of its quantification estimates. This is performed by bootstrap sampling of the original read mappings, and subsequently performing inference under each resampling.  These inferential replicates allow assessing the variance of the point estimate of transcript abundance, and can lead to improved differential analysis at the transcript level, if using a differential testing tool that takes advantage of this information. The generation of inferential replicates is controlled by the <code>--num-bootstraps</code> argument to <code>oarfish</code>.  The default value is <code>0</code>, meaning that no inferential replicates are generated.  If you set this to some value greater than <code>0</code>, the the requested number of inferential replicates will be generated. It is recommended, if generating inferential replicates, to run <code>oarfish</code> with multiple threads, since replicate generation is highly-parallelized. Finally, if replicates are generated, they are written to a <code>Parquet</code>, starting with the specified output stem and ending with <code>infreps.pq</code>.</p>"},{"location":"#output","title":"Output","text":"<p>The <code>--output</code> option passed to <code>oarfish</code> corresponds to a path prefix (this prefix can contain the path separator character and if it refers to a directory that does not yeat exist, that directory will be created). Based on this path prefix, say <code>P</code>, <code>oarfish</code> will create 2 files:</p> <ul> <li><code>P.meta_info.json</code> - a JSON format file containing information about relevant parameters with which <code>oarfish</code> was run, and other relevant inforamtion from the processed sample apart from the actual transcript quantifications.</li> <li><code>P.quant</code> - a tab separated file listing the quantified targets, as well as information about their length and other metadata. The <code>num_reads</code> column provides the estimate of the number of reads originating from each target.</li> <li><code>P.infreps.pq</code> - a <code>Parquet</code> table where each row is a transcript and each column is an inferential replicate, containing the estimated counts for each transcript under each computed inferential replicate.</li> <li><code>P.ambig_info.tsv</code> - a tab separated file listing, for each transcript (in the same order in which they appear in <code>P.quant</code>) the number of uniquely mapped, ambiguously mapped, and total reads.  The quantification estimate for each transcript, in general, should reside between the number of uniquely aligned reads and the total number of reads (i.e. these provide, respectively lower and upper bounds for the number of reads assigned to each transcript).  Note that the total in this file is the total number of reads that align to this transcript with a sufficiently high alignment score --- it is not, in general, an estimate of the number of reads originating from this transcript as many of those reads can be multimapping and, in fact, potentially better described by other transcripts.</li> <li><code>P.prob[.lz4]</code> - a file encoding the assignment probability of each read to each transcript to which it had a valid alignment (optionally compressed using <code>lz4</code>). This file is optional and is generated only if <code>--write-assignment-probs</code> is passed to <code>oarfish</code>.</li> </ul>"},{"location":"#references","title":"References","text":"<ol> <li> <p>Josie Gleeson, Adrien Leger, Yair D J Prawer, Tracy A Lane, Paul J Harrison, Wilfried Haerty, Michael B Clark, Accurate expression quantification from nanopore direct RNA sequencing with NanoCount, Nucleic Acids Research, Volume 50, Issue 4, 28 February 2022, Page e19, https://doi.org/10.1093/nar/gkab1129 \u21a9</p> </li> <li> <p>Zahra Zare Jousheghani, Rob Patro. Oarfish: Enhanced probabilistic modeling leads to improved accuracy in long read transcriptome quantification, bioRxiv 2024.02.28.582591; doi: https://doi.org/10.1101/2024.02.28.582591 \u21a9</p> </li> </ol>"}]}